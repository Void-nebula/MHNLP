{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import RobertaTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import RobertaConfig\n",
    "from transformers import RobertaModel, RobertaPreTrainedModel\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskRobertaModel(RobertaPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        # Roberta base model without pooling layer\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        \n",
    "        # Classifier for overall symptom presence: 4 labels (both, depression, anxiety, none)\n",
    "        self.symptom_classifier = nn.Linear(config.hidden_size, 4)\n",
    "        \n",
    "        # Classifier for depression states: 6 labels (0-5)\n",
    "        self.depression_classifier = nn.Linear(config.hidden_size, 6)\n",
    "        \n",
    "        # Classifier for anxiety states: 7 labels (0-6)\n",
    "        self.anxiety_classifier = nn.Linear(config.hidden_size, 7)\n",
    "\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "        # Uncertainty Weight Parameters\n",
    "        self.sigma_symptom = nn.Parameter(torch.ones(1))\n",
    "        self.sigma_depression = nn.Parameter(torch.ones(1))\n",
    "        self.sigma_anxiety = nn.Parameter(torch.ones(1))\n",
    "\n",
    "        # Initialize weights\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None, depression_labels=None, anxiety_labels=None):\n",
    "        # Get Roberta outputs\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Get pooled [CLS] token output\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "\n",
    "        # Overall symptom classification logits\n",
    "        symptom_logits = self.symptom_classifier(pooled_output)\n",
    "        \n",
    "        # Depression state classification logits\n",
    "        depression_logits = self.depression_classifier(pooled_output)\n",
    "\n",
    "        # Anxiety state classification logits\n",
    "        anxiety_logits = self.anxiety_classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None and depression_labels is not None and anxiety_labels is not None:\n",
    "            # Loss function\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            # Calculate individual losses for each task\n",
    "            symptom_loss = loss_fct(symptom_logits, labels)\n",
    "            depression_loss = loss_fct(depression_logits, depression_labels)\n",
    "            anxiety_loss = loss_fct(anxiety_logits, anxiety_labels)\n",
    "\n",
    "            # Combine losses\n",
    "            # loss = symptom_loss + depression_loss + anxiety_loss\n",
    "            \n",
    "            # Uncertainty Weighted Loss\n",
    "            total_loss = (\n",
    "            (1 / (2 * self.sigma_symptom ** 2)) * symptom_loss +\n",
    "            (1 / (2 * self.sigma_depression ** 2)) * depression_loss +\n",
    "            (1 / (2 * self.sigma_anxiety ** 2)) * anxiety_loss +\n",
    "            torch.log(self.sigma_symptom * self.sigma_depression * self.sigma_anxiety)\n",
    "            )\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=(symptom_logits, depression_logits, anxiety_logits),\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    total_symptom_correct = 0\n",
    "    total_depression_correct = 0\n",
    "    total_anxiety_correct = 0\n",
    "\n",
    "    total_items = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)  # Symptom classification labels\n",
    "            depression_labels = batch['depression_labels'].to(device)  # Depression state labels\n",
    "            anxiety_labels = batch['anxiety_labels'].to(device)  # Anxiety state labels\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            # Unpack logits\n",
    "            symptom_logits = outputs.logits[0]  # Symptom classification logits\n",
    "            depression_logits = outputs.logits[1]  # Depression state logits\n",
    "            anxiety_logits = outputs.logits[2]  # Anxiety state logits\n",
    "\n",
    "            # Symptom classification predictions\n",
    "            _, symptom_preds = torch.max(symptom_logits, dim=1)\n",
    "            total_symptom_correct += torch.sum(symptom_preds == labels)\n",
    "\n",
    "            # Depression state classification predictions (only if predicted as depression or both)\n",
    "            _, depression_preds = torch.max(depression_logits, dim=1)\n",
    "            valid_depression_indices = (labels == 1) | (labels == 0)  # Labels 1 (depression) and 0 (both)\n",
    "            total_depression_correct += torch.sum(depression_preds[valid_depression_indices] == depression_labels[valid_depression_indices])\n",
    "\n",
    "            # Anxiety state classification predictions (only if predicted as anxiety or both)\n",
    "            _, anxiety_preds = torch.max(anxiety_logits, dim=1)\n",
    "            valid_anxiety_indices = (labels == 2) | (labels == 0)  # Labels 2 (anxiety) and 0 (both)\n",
    "            total_anxiety_correct += torch.sum(anxiety_preds[valid_anxiety_indices] == anxiety_labels[valid_anxiety_indices])\n",
    "\n",
    "            # Count total items\n",
    "            total_items += labels.size(0)\n",
    "\n",
    "    # Compute accuracies\n",
    "    symptom_accuracy = total_symptom_correct.double() / total_items\n",
    "    depression_accuracy = total_depression_correct.double() / valid_depression_indices.sum().double()\n",
    "    anxiety_accuracy = total_anxiety_correct.double() / valid_anxiety_indices.sum().double()\n",
    "\n",
    "    print(f'Symptom Classification Accuracy: {symptom_accuracy:.4f}')\n",
    "    print(f'Depression State Accuracy: {depression_accuracy:.4f}')\n",
    "    print(f'Anxiety State Accuracy: {anxiety_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Define the dataset class to handle the CSV\n",
    "    class MentalHealthDataset(Dataset):\n",
    "        def __init__(self, file_path, tokenizer, max_length=512):\n",
    "            self.data = pd.read_csv(file_path)\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_length = max_length\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            # Extract the text and the labels from the dataset\n",
    "            text = self.data.loc[index, 'text']\n",
    "            symptom_label = int(self.data.loc[index, 'disorder'])  # overall disorder label (both, depression, anxiety, none)\n",
    "            depression_label = int(self.data.loc[index, 'depression_state'])  # depression state (0-5)\n",
    "            anxiety_label = int(self.data.loc[index, 'anxiety_state'])  # anxiety state (0-6)\n",
    "\n",
    "            # Tokenize the text\n",
    "            inputs = self.tokenizer(\n",
    "                text,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "            # Return a dictionary of inputs and labels\n",
    "            return {\n",
    "                'input_ids': inputs['input_ids'].squeeze(),  # remove the batch dimension\n",
    "                'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "                'labels': torch.tensor(symptom_label, dtype=torch.long),\n",
    "                'depression_labels': torch.tensor(depression_label, dtype=torch.long),\n",
    "                'anxiety_labels': torch.tensor(anxiety_label, dtype=torch.long)\n",
    "            }\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = MentalHealthDataset('train_data_customize_hybrid_class_classification_depression.csv', tokenizer)\n",
    "    val_dataset = MentalHealthDataset('val_data_customize_hybrid_class_classification_depression.csv', tokenizer)\n",
    "    test_dataset = MentalHealthDataset('test_data_customize_hybrid_class_classification_depression.csv', tokenizer)\n",
    "\n",
    "    # Define batch size\n",
    "    batch_size = 16\n",
    "\n",
    "    # Create DataLoader for each dataset\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Load configuration for Roberta\n",
    "    config = RobertaConfig.from_pretrained('roberta-base')\n",
    "\n",
    "    # Initialize your multi-task classification model\n",
    "    model = MultiTaskRobertaModel(config)\n",
    "\n",
    "    # Define optimizer and scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "    # Move model to GPU if available\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct_predictions = 0\n",
    "\n",
    "        for step, batch in enumerate(train_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            depression_labels = batch['depression_labels'].to(device)\n",
    "            anxiety_labels = batch['anxiety_labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                            labels=labels, depression_labels=depression_labels, anxiety_labels=anxiety_labels)\n",
    "\n",
    "            # compute loss\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if step%2 == 0:\n",
    "                print(f\"Step {step}/{len(train_loader)} - Current Loss: {loss.item():.4f}\")\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch {epoch + 1}, Loss: {avg_loss:.4f}')\n",
    "    torch.save(model, \"multi_task_roberta_full_model.pth\")\n",
    "    # Evaluate on validation set\n",
    "    evaluate_model(model, val_loader)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    evaluate_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
