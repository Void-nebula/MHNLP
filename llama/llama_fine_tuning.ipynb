{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 18:00:54.318844: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733248854.333523  271940 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733248854.338086  271940 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-03 18:00:54.353627: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b378e78a6dc440a81221713d9a6acb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_8bit=True,\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2490083c29441095b116c17c9c46f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5b63f01270446191a8b88fa12d8b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Length: 500.0\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['messages', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 800\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['messages', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"/home/txie/Mental_Health/CS_584_Course_Project/MHNLP/fine_tuning_dataset.jsonl\")\n",
    "\n",
    "def preprocess_data(batch):\n",
    "    results = {\n",
    "        \"input_ids\": [],\n",
    "        \"attention_mask\": [],\n",
    "        \"labels\": []\n",
    "    }\n",
    "\n",
    "    for example in batch['messages']:\n",
    "        prompt = \"\"\n",
    "        completion = \"\"\n",
    "\n",
    "        for message in example:\n",
    "            if message[\"role\"] in [\"system\", \"user\"]:\n",
    "                prompt += f\"{message['role'].capitalize()}: {message['content']}\\n\"\n",
    "            elif message[\"role\"] == \"assistant\":\n",
    "                completion = message[\"content\"]\n",
    "\n",
    "        # Tokenize Prompt and Completion\n",
    "        tokenized = tokenizer(\n",
    "            text=prompt.strip(),\n",
    "            text_target=completion.strip(),\n",
    "            truncation=True,\n",
    "            max_length=500,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "\n",
    "        results[\"input_ids\"].append(tokenized[\"input_ids\"])\n",
    "        results[\"attention_mask\"].append(tokenized[\"attention_mask\"])\n",
    "        results[\"labels\"].append(tokenized[\"labels\"])\n",
    "\n",
    "    return results\n",
    "\n",
    "# Dataset preprocessing\n",
    "tokenized_dataset = dataset.map(preprocess_data, batched=True)\n",
    "\n",
    "# def tokenize_function(batch):\n",
    "#     return tokenizer(batch[\"text\"], truncation=True, padding=True, max_length=300)\n",
    "\n",
    "\n",
    "# tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# def process_labels(examples):\n",
    "#     examples[\"label\"] = [int(label) for label in examples[\"label\"]]\n",
    "#     return examples\n",
    "\n",
    "# tokenized_dataset = tokenized_dataset.map(process_labels)\n",
    "\n",
    "train_test_split = tokenized_dataset[\"train\"].train_test_split(test_size=0.2)\n",
    "\n",
    "# Create a tokenized dataset with the train and test splits\n",
    "tokenized_dataset = DatasetDict({\n",
    "    \"train\": train_test_split[\"train\"],\n",
    "    \"validation\": train_test_split[\"test\"]\n",
    "})\n",
    "\n",
    "lengths = [len(data[\"input_ids\"]) for data in tokenized_dataset[\"train\"]]\n",
    "print(f\"Average Length: {sum(lengths) / len(lengths)}\")\n",
    "\n",
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'role': 'system', 'content': 'You are a professional therapist. Your patient is telling you about their basic information and some answers to a mental health servey. Based on the information, please infer whether the patient has depression and/or anxiety disorders. 0: Neither, 1: Either or both. Based on this correspondence, you only need to answer the number.'}, {'role': 'user', 'content': \"Age: 42. Sex: Female. Race: White. Sexual orientation: Bisexual, Queer. Financial situation right now: Rarely stressful. Financial situation while growing up: Always stressful. Within the last 12 months I never worried about not having stable housing. I am currently enrolled in a degree of Master's program. I am currently enrolled as a full-time student. My current overall GPA is no grade. I felt that emotional or mental difficulties have hurt my academic performance for none in the last 12 months. I am not sure that I am confident I will be able to finish my degree no matter what challenges I may face. I disagree with that I see myself as a part of the campus community. It's somewhat difficult that PHQ9 questions (depression) made it for me to do my work, take care of things at home, or get along with other people. It's somewhat difficult that GAD7 questions (anxiety) made it for me to do my work, take care of things at home, or get along with other people. \"}, {'role': 'assistant', 'content': '0'}], 'input_ids': [1, 2184, 29901, 887, 526, 263, 10257, 29220, 481, 391, 29889, 3575, 16500, 338, 14509, 366, 1048, 1009, 6996, 2472, 322, 777, 6089, 304, 263, 19119, 9045, 724, 6950, 29889, 16564, 373, 278, 2472, 29892, 3113, 10115, 3692, 278, 16500, 756, 316, 2590, 322, 29914, 272, 14919, 21549, 766, 20488, 29889, 29871, 29900, 29901, 2448, 2121, 29892, 29871, 29896, 29901, 20370, 470, 1716, 29889, 16564, 373, 445, 3928, 663, 29892, 366, 871, 817, 304, 1234, 278, 1353, 29889, 13, 2659, 29901, 16767, 29901, 29871, 29946, 29906, 29889, 21703, 29901, 19361, 744, 29889, 23613, 29901, 8037, 29889, 21703, 950, 19843, 29901, 16818, 735, 950, 29892, 5462, 261, 29889, 4231, 273, 1455, 6434, 1492, 1286, 29901, 390, 598, 368, 22884, 1319, 29889, 4231, 273, 1455, 6434, 1550, 15678, 701, 29901, 29849, 22884, 1319, 29889, 23732, 278, 1833, 29871, 29896, 29906, 7378, 306, 2360, 6365, 1255, 1048, 451, 2534, 13714, 27261, 29889, 306, 626, 5279, 427, 24476, 297, 263, 7426, 310, 9082, 29915, 29879, 1824, 29889, 306, 626, 5279, 427, 24476, 408, 263, 2989, 29899, 2230, 8368, 29889, 1619, 1857, 12463, 402, 7228, 338, 694, 19468, 29889, 306, 7091, 393, 23023, 1848, 470, 19119, 23553, 505, 21682, 590, 21567, 4180, 363, 5642, 297, 278, 1833, 29871, 29896, 29906, 7378, 29889, 306, 626, 451, 1854, 393, 306, 626, 24332, 306, 674, 367, 2221, 304, 8341, 590, 7426, 694, 4383, 825, 18066, 267, 306, 1122, 3700, 29889, 306, 22941, 929, 411, 393, 306, 1074, 6142, 408, 263, 760, 310, 278, 24165, 7881, 29889, 739, 29915, 29879, 10579, 5189, 393, 349, 29950, 29984, 29929, 5155, 313, 311, 2590, 29897, 1754, 372, 363, 592, 304, 437, 590, 664, 29892, 2125, 2562, 310, 2712, 472, 3271, 29892, 470, 679, 3412, 411, 916, 2305, 29889, 739, 29915, 29879, 10579, 5189, 393, 402, 3035, 29955, 5155, 313, 273, 29916, 21549, 29897, 1754, 372, 363, 592, 304, 437, 590, 664, 29892, 2125, 2562, 310, 2712, 472, 3271, 29892, 470, 679, 3412, 411, 916, 2305, 29889, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [1, 29871, 29900, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset[\"train\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/home/txie/Mental_Health/CS_584_Course_Project/MHNLP/\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    "    evaluation_strategy=\"steps\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model.save_pretrained(\"/home/txie/Mental_Health/CS_584_Course_Project/MHNLP/fine_tuned\", save_embedding_layers=True)\n",
    "tokenizer.save_pretrained(\"/home/txie/Mental_Health/CS_584_Course_Project/MHNLP/fine_tuned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
